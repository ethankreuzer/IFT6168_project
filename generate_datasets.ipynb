{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detecting 3 CUDA device(s).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import importlib\n",
    "sys.path.append('/home/ethan/IFT6168/project/dcdi/data/generation')\n",
    "\n",
    "import generate_data\n",
    "importlib.reload(generate_data)\n",
    "\n",
    "from generate_data import dataset_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Generating data: 10 nodes, replicate 1/5 ===\n",
      "Sampling the DAG #0\n",
      "\n",
      "=== Generating data: 10 nodes, replicate 2/5 ===\n",
      "Cannot create the folder: data_p10_e30_n10000_scaling_nodes_p10\n",
      "Sampling the DAG #1\n",
      "\n",
      "=== Generating data: 10 nodes, replicate 3/5 ===\n",
      "Cannot create the folder: data_p10_e30_n10000_scaling_nodes_p10\n",
      "Sampling the DAG #2\n",
      "\n",
      "=== Generating data: 10 nodes, replicate 4/5 ===\n",
      "Cannot create the folder: data_p10_e30_n10000_scaling_nodes_p10\n",
      "Sampling the DAG #3\n",
      "\n",
      "=== Generating data: 10 nodes, replicate 5/5 ===\n",
      "Cannot create the folder: data_p10_e30_n10000_scaling_nodes_p10\n",
      "Sampling the DAG #4\n",
      "\n",
      "=== Generating data: 20 nodes, replicate 1/5 ===\n",
      "Sampling the DAG #0\n",
      "\n",
      "=== Generating data: 20 nodes, replicate 2/5 ===\n",
      "Cannot create the folder: data_p20_e60_n10000_scaling_nodes_p20\n",
      "Sampling the DAG #1\n",
      "\n",
      "=== Generating data: 20 nodes, replicate 3/5 ===\n",
      "Cannot create the folder: data_p20_e60_n10000_scaling_nodes_p20\n",
      "Sampling the DAG #2\n",
      "\n",
      "=== Generating data: 20 nodes, replicate 4/5 ===\n",
      "Cannot create the folder: data_p20_e60_n10000_scaling_nodes_p20\n",
      "Sampling the DAG #3\n",
      "\n",
      "=== Generating data: 20 nodes, replicate 5/5 ===\n",
      "Cannot create the folder: data_p20_e60_n10000_scaling_nodes_p20\n",
      "Sampling the DAG #4\n",
      "\n",
      "=== Generating data: 30 nodes, replicate 1/5 ===\n",
      "Sampling the DAG #0\n",
      "\n",
      "=== Generating data: 30 nodes, replicate 2/5 ===\n",
      "Cannot create the folder: data_p30_e90_n10000_scaling_nodes_p30\n",
      "Sampling the DAG #1\n",
      "\n",
      "=== Generating data: 30 nodes, replicate 3/5 ===\n",
      "Cannot create the folder: data_p30_e90_n10000_scaling_nodes_p30\n",
      "Sampling the DAG #2\n",
      "\n",
      "=== Generating data: 30 nodes, replicate 4/5 ===\n",
      "Cannot create the folder: data_p30_e90_n10000_scaling_nodes_p30\n",
      "Sampling the DAG #3\n",
      "\n",
      "=== Generating data: 30 nodes, replicate 5/5 ===\n",
      "Cannot create the folder: data_p30_e90_n10000_scaling_nodes_p30\n",
      "Sampling the DAG #4\n",
      "\n",
      "=== Generating data: 40 nodes, replicate 1/5 ===\n",
      "Sampling the DAG #0\n",
      "\n",
      "=== Generating data: 40 nodes, replicate 2/5 ===\n",
      "Cannot create the folder: data_p40_e120_n10000_scaling_nodes_p40\n",
      "Sampling the DAG #1\n",
      "\n",
      "=== Generating data: 40 nodes, replicate 3/5 ===\n",
      "Cannot create the folder: data_p40_e120_n10000_scaling_nodes_p40\n",
      "Sampling the DAG #2\n",
      "\n",
      "=== Generating data: 40 nodes, replicate 4/5 ===\n",
      "Cannot create the folder: data_p40_e120_n10000_scaling_nodes_p40\n",
      "Sampling the DAG #3\n",
      "\n",
      "=== Generating data: 40 nodes, replicate 5/5 ===\n",
      "Cannot create the folder: data_p40_e120_n10000_scaling_nodes_p40\n",
      "Sampling the DAG #4\n",
      "\n",
      "=== Generating data: 50 nodes, replicate 1/5 ===\n",
      "Sampling the DAG #0\n",
      "\n",
      "=== Generating data: 50 nodes, replicate 2/5 ===\n",
      "Cannot create the folder: data_p50_e150_n10000_scaling_nodes_p50\n",
      "Sampling the DAG #1\n",
      "\n",
      "=== Generating data: 50 nodes, replicate 3/5 ===\n",
      "Cannot create the folder: data_p50_e150_n10000_scaling_nodes_p50\n",
      "Sampling the DAG #2\n",
      "\n",
      "=== Generating data: 50 nodes, replicate 4/5 ===\n",
      "Cannot create the folder: data_p50_e150_n10000_scaling_nodes_p50\n",
      "Sampling the DAG #3\n",
      "\n",
      "=== Generating data: 50 nodes, replicate 5/5 ===\n",
      "Cannot create the folder: data_p50_e150_n10000_scaling_nodes_p50\n",
      "Sampling the DAG #4\n"
     ]
    }
   ],
   "source": [
    "common_args = dict(\n",
    "    mechanism='nn',\n",
    "    cause='gaussian',\n",
    "    intervention_type='structural',\n",
    "    struct_interv_distr='normal',\n",
    "    noise='gaussian',\n",
    "    noise_coeff=0.25,\n",
    "    nb_points=10000,\n",
    "    rescale=False,\n",
    "    obs_data=True,\n",
    "    nb_interventions=10,\n",
    "    min_nb_target=1,\n",
    "    max_nb_target=10,\n",
    "    conservative=False,\n",
    "    cover=False,\n",
    "    verbose=True,\n",
    "    expected_degree=3\n",
    ")\n",
    "\n",
    "# Number of nodes to iterate over\n",
    "node_sizes = [10, 20, 30, 40, 50]\n",
    "\n",
    "# Datasets per configuration\n",
    "n_datasets = 5\n",
    "\n",
    "for n_nodes in node_sizes:\n",
    "    for i in range(n_datasets):\n",
    "        print(f\"\\n=== Generating data: {n_nodes} nodes, replicate {i+1}/{n_datasets} ===\")\n",
    "        gen = dataset_generator(\n",
    "            nb_nodes=n_nodes,\n",
    "            suffix=f'scaling_nodes_p{n_nodes}',  # folder will reflect node count\n",
    "            **common_args\n",
    "        )\n",
    "        gen.i_dataset = i\n",
    "        gen.generator = None\n",
    "        gen.generate(intervention=False)\n",
    "        gen.generate(intervention=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.22 ('dcdfg_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa1ae255cd3035572db8027a8c685be87aec9c007acc3448eb313fbefc5b1a5e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
