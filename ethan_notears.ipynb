{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4e9f3a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os\n",
    "from notears.notears import linear\n",
    "from notears.notears import utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b870e3e",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e0695ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_linear_struct'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff8aad9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dag_path = os.path.join(data_dir, 'DAG1.npy')\n",
    "cpdag_path = os.path.join(data_dir, 'CPDAG1.npy')\n",
    "obs_data_path = os.path.join(data_dir, 'data1.npy')\n",
    "interv_data_path = os.path.join(data_dir, 'data_interv1.npy')\n",
    "regime_idx_path = os.path.join(data_dir, 'regime1.csv')\n",
    "interv_nodes_path = os.path.join(data_dir, 'intervention1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc422103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dag = np.load(dag_path)\n",
    "dag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ece1a77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 1., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpdag = np.load(cpdag_path)\n",
    "cpdag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3e05eb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04549416,  1.56876855,  0.50505903, ..., -1.55214666,\n",
       "        -0.67011774, -0.95467569],\n",
       "       [ 0.83139287,  0.29945842, -0.56516481, ..., -0.82588713,\n",
       "        -1.0324189 , -0.20330703],\n",
       "       [-1.53261836, -2.29737887,  0.70926069, ...,  1.30303601,\n",
       "         2.05855852,  0.90334801],\n",
       "       ...,\n",
       "       [-1.68027651, -1.29201461,  0.36296983, ...,  0.20386925,\n",
       "         0.3136674 ,  1.03691721],\n",
       "       [ 0.73037723,  0.7762301 ,  0.5579628 , ..., -0.08943212,\n",
       "        -1.72667629, -0.31639158],\n",
       "       [-2.34830366, -2.29520103, -0.47288351, ...,  1.47536252,\n",
       "         1.07835087,  2.56914919]], shape=(10000, 10))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data = np.load(obs_data_path)\n",
    "obs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "532ce8da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "10",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0ece2ab6-9679-4708-9acd-84e56acbaf0d",
       "rows": [
        [
         "0",
         "10"
        ],
        [
         "1",
         "10"
        ],
        [
         "2",
         "10"
        ],
        [
         "3",
         "10"
        ],
        [
         "4",
         "10"
        ],
        [
         "5",
         "10"
        ],
        [
         "6",
         "10"
        ],
        [
         "7",
         "10"
        ],
        [
         "8",
         "10"
        ],
        [
         "9",
         "10"
        ],
        [
         "10",
         "10"
        ],
        [
         "11",
         "10"
        ],
        [
         "12",
         "10"
        ],
        [
         "13",
         "10"
        ],
        [
         "14",
         "10"
        ],
        [
         "15",
         "10"
        ],
        [
         "16",
         "10"
        ],
        [
         "17",
         "10"
        ],
        [
         "18",
         "10"
        ],
        [
         "19",
         "10"
        ],
        [
         "20",
         "10"
        ],
        [
         "21",
         "10"
        ],
        [
         "22",
         "10"
        ],
        [
         "23",
         "10"
        ],
        [
         "24",
         "10"
        ],
        [
         "25",
         "10"
        ],
        [
         "26",
         "10"
        ],
        [
         "27",
         "10"
        ],
        [
         "28",
         "10"
        ],
        [
         "29",
         "10"
        ],
        [
         "30",
         "10"
        ],
        [
         "31",
         "10"
        ],
        [
         "32",
         "10"
        ],
        [
         "33",
         "10"
        ],
        [
         "34",
         "10"
        ],
        [
         "35",
         "10"
        ],
        [
         "36",
         "10"
        ],
        [
         "37",
         "10"
        ],
        [
         "38",
         "10"
        ],
        [
         "39",
         "10"
        ],
        [
         "40",
         "10"
        ],
        [
         "41",
         "10"
        ],
        [
         "42",
         "10"
        ],
        [
         "43",
         "10"
        ],
        [
         "44",
         "10"
        ],
        [
         "45",
         "10"
        ],
        [
         "46",
         "10"
        ],
        [
         "47",
         "10"
        ],
        [
         "48",
         "10"
        ],
        [
         "49",
         "10"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9999
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      10\n",
       "0     10\n",
       "1     10\n",
       "2     10\n",
       "3     10\n",
       "4     10\n",
       "...   ..\n",
       "9994   0\n",
       "9995   0\n",
       "9996   0\n",
       "9997   0\n",
       "9998   0\n",
       "\n",
       "[9999 rows x 1 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regime_df = pd.read_csv(regime_idx_path)\n",
    "regime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "dc5b5cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1b5b20e6-708b-440b-9604-43d4720f9aba",
       "rows": [
        [
         "0",
         "0"
        ],
        [
         "1",
         "0"
        ],
        [
         "2",
         "0"
        ],
        [
         "3",
         "0"
        ],
        [
         "4",
         "0"
        ],
        [
         "5",
         "0"
        ],
        [
         "6",
         "0"
        ],
        [
         "7",
         "0"
        ],
        [
         "8",
         "0"
        ],
        [
         "9",
         "0"
        ],
        [
         "10",
         "0"
        ],
        [
         "11",
         "0"
        ],
        [
         "12",
         "0"
        ],
        [
         "13",
         "0"
        ],
        [
         "14",
         "0"
        ],
        [
         "15",
         "0"
        ],
        [
         "16",
         "0"
        ],
        [
         "17",
         "0"
        ],
        [
         "18",
         "0"
        ],
        [
         "19",
         "0"
        ],
        [
         "20",
         "0"
        ],
        [
         "21",
         "0"
        ],
        [
         "22",
         "0"
        ],
        [
         "23",
         "0"
        ],
        [
         "24",
         "0"
        ],
        [
         "25",
         "0"
        ],
        [
         "26",
         "0"
        ],
        [
         "27",
         "0"
        ],
        [
         "28",
         "0"
        ],
        [
         "29",
         "0"
        ],
        [
         "30",
         "0"
        ],
        [
         "31",
         "0"
        ],
        [
         "32",
         "0"
        ],
        [
         "33",
         "0"
        ],
        [
         "34",
         "0"
        ],
        [
         "35",
         "0"
        ],
        [
         "36",
         "0"
        ],
        [
         "37",
         "0"
        ],
        [
         "38",
         "0"
        ],
        [
         "39",
         "0"
        ],
        [
         "40",
         "0"
        ],
        [
         "41",
         "0"
        ],
        [
         "42",
         "0"
        ],
        [
         "43",
         "0"
        ],
        [
         "44",
         "0"
        ],
        [
         "45",
         "0"
        ],
        [
         "46",
         "0"
        ],
        [
         "47",
         "0"
        ],
        [
         "48",
         "0"
        ],
        [
         "49",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 9090
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9085</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9086</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9087</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9088</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9089</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9090 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "...  ..\n",
       "9085  3\n",
       "9086  3\n",
       "9087  3\n",
       "9088  3\n",
       "9089  3\n",
       "\n",
       "[9090 rows x 1 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interv_nodes_df = pd.read_csv(interv_nodes_path)\n",
    "interv_nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bc777907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as slin\n",
    "import scipy.optimize as sopt\n",
    "from scipy.special import expit as sigmoid\n",
    "\n",
    "\n",
    "def notears_linear(X, lambda1, loss_type, max_iter=100, h_tol=1e-8, rho_max=1e+16, w_threshold=0.3):\n",
    "    \"\"\"Solve min_W L(W; X) + lambda1 â€–Wâ€–_1 s.t. h(W) = 0 using augmented Lagrangian.\n",
    "\n",
    "    Args:\n",
    "        X (np.ndarray): [n, d] sample matrix\n",
    "        lambda1 (float): l1 penalty parameter\n",
    "        loss_type (str): l2, logistic, poisson\n",
    "        max_iter (int): max num of dual ascent steps\n",
    "        h_tol (float): exit if |h(w_est)| <= htol\n",
    "        rho_max (float): exit if rho >= rho_max\n",
    "        w_threshold (float): drop edge if |weight| < threshold\n",
    "\n",
    "    Returns:\n",
    "        W_est (np.ndarray): [d, d] estimated DAG\n",
    "    \"\"\"\n",
    "    def _loss(W):\n",
    "        \"\"\"Evaluate value and gradient of loss.\"\"\"\n",
    "        M = X @ W\n",
    "        if loss_type == 'l2':\n",
    "            R = X - M\n",
    "            loss = 0.5 / X.shape[0] * (R ** 2).sum()\n",
    "            G_loss = - 1.0 / X.shape[0] * X.T @ R\n",
    "        elif loss_type == 'logistic':\n",
    "            loss = 1.0 / X.shape[0] * (np.logaddexp(0, M) - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (sigmoid(M) - X)\n",
    "        elif loss_type == 'poisson':\n",
    "            S = np.exp(M)\n",
    "            loss = 1.0 / X.shape[0] * (S - X * M).sum()\n",
    "            G_loss = 1.0 / X.shape[0] * X.T @ (S - X)\n",
    "        else:\n",
    "            raise ValueError('unknown loss type')\n",
    "        return loss, G_loss\n",
    "\n",
    "    def _h(W):\n",
    "        \"\"\"Evaluate value and gradient of acyclicity constraint.\"\"\"\n",
    "        E = slin.expm(W * W)  # (Zheng et al. 2018)\n",
    "        h = np.trace(E) - d\n",
    "        #     # A different formulation, slightly faster at the cost of numerical stability\n",
    "        #     M = np.eye(d) + W * W / d  # (Yu et al. 2019)\n",
    "        #     E = np.linalg.matrix_power(M, d - 1)\n",
    "        #     h = (E.T * M).sum() - d\n",
    "        G_h = E.T * W * 2\n",
    "        return h, G_h\n",
    "\n",
    "    def _adj(w):\n",
    "        \"\"\"Convert doubled variables ([2 d^2] array) back to original variables ([d, d] matrix).\"\"\"\n",
    "        return (w[:d * d] - w[d * d:]).reshape([d, d])\n",
    "\n",
    "    def _func(w):\n",
    "        \"\"\"Evaluate value and gradient of augmented Lagrangian for doubled variables ([2 d^2] array).\"\"\"\n",
    "        W = _adj(w)\n",
    "        loss, G_loss = _loss(W)\n",
    "        h, G_h = _h(W)\n",
    "        obj = loss + 0.5 * rho * h * h + alpha * h + lambda1 * w.sum()\n",
    "        G_smooth = G_loss + (rho * h + alpha) * G_h\n",
    "        g_obj = np.concatenate((G_smooth + lambda1, - G_smooth + lambda1), axis=None)\n",
    "        return obj, g_obj\n",
    "\n",
    "    n, d = X.shape\n",
    "    w_est, rho, alpha, h = np.zeros(2 * d * d), 1.0, 0.0, np.inf  # double w_est into (w_pos, w_neg)\n",
    "    bnds = [(0, 0) if i == j else (0, None) for _ in range(2) for i in range(d) for j in range(d)]\n",
    "    if loss_type == 'l2':\n",
    "        X = X - np.mean(X, axis=0, keepdims=True)\n",
    "    for _ in range(max_iter):\n",
    "        w_new, h_new = None, None\n",
    "        while rho < rho_max:\n",
    "            sol = sopt.minimize(_func, w_est, method='L-BFGS-B', jac=True, bounds=bnds)\n",
    "            w_new = sol.x\n",
    "            h_new, _ = _h(_adj(w_new))\n",
    "            if h_new > 0.25 * h:\n",
    "                rho *= 10\n",
    "            else:\n",
    "                break\n",
    "        w_est, h = w_new, h_new\n",
    "        alpha += rho * h\n",
    "        if h <= h_tol or rho >= rho_max:\n",
    "            break\n",
    "    W_est = _adj(w_est)\n",
    "    W_est[np.abs(W_est) < w_threshold] = 0\n",
    "    return W_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fb885d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run NOTears on obs_data\n",
    "lambda1 = 0.1  # L1 penalty parameter\n",
    "loss_type = 'l2'  # Loss type (choose 'l2', 'logistic', or 'poisson')\n",
    "w_threshold = 0.3 #suggested from paper\n",
    "\n",
    "W_est = notears_linear(obs_data, lambda1=lambda1, loss_type=loss_type)\n",
    "W_est[np.abs(W_est) < w_threshold] = 0\n",
    "\n",
    "output_path = \"/home/ethan/IFT6168/project/exp/test_W_est_obs_data.csv\"\n",
    "np.savetxt(output_path, W_est, delimiter=\",\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01b0de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.39957201,  0.        ,  0.        , -0.69088491],\n",
       "       [ 0.58321253,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        , -0.5920318 , -0.77126585,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , -0.76201477,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        , -0.71167991,  0.        ,  0.        ,  0.        ,\n",
       "         0.        , -0.82845639,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_est"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630c820",
   "metadata": {},
   "source": [
    "# Test all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c446f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nnadd_struct\n",
      "Dataset 1: SHD = 9\n",
      "Dataset 2: SHD = 16\n",
      "Dataset 3: SHD = 5\n",
      "Dataset 4: SHD = 21\n",
      "Dataset 5: SHD = 13\n",
      "Dataset 6: SHD = 8\n",
      "Dataset 7: SHD = 19\n",
      "Dataset 8: SHD = 13\n",
      "Dataset 9: SHD = 10\n",
      "Dataset 10: SHD = 14\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nnadd_struct: 12.8\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nnadd_struct: 22.360000000000003\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nn_struct\n",
      "Dataset 1: SHD = 11\n",
      "Dataset 2: SHD = 14\n",
      "Dataset 3: SHD = 9\n",
      "Dataset 4: SHD = 14\n",
      "Dataset 5: SHD = 13\n",
      "Dataset 6: SHD = 13\n",
      "Dataset 7: SHD = 12\n",
      "Dataset 8: SHD = 9\n",
      "Dataset 9: SHD = 7\n",
      "Dataset 10: SHD = 11\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nn_struct: 11.3\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nn_struct: 5.010000000000001\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nnadd_struct\n",
      "Dataset 1: SHD = 45\n",
      "Dataset 2: SHD = 38\n",
      "Dataset 3: SHD = 37\n",
      "Dataset 4: SHD = 33\n",
      "Dataset 5: SHD = 37\n",
      "Dataset 6: SHD = 44\n",
      "Dataset 7: SHD = 42\n",
      "Dataset 8: SHD = 40\n",
      "Dataset 9: SHD = 33\n",
      "Dataset 10: SHD = 42\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nnadd_struct: 39.1\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nnadd_struct: 16.09\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nn_struct\n",
      "Dataset 1: SHD = 76\n",
      "Dataset 2: SHD = 89\n",
      "Dataset 3: SHD = 62\n",
      "Dataset 4: SHD = 94\n",
      "Dataset 5: SHD = 80\n",
      "Dataset 6: SHD = 63\n",
      "Dataset 7: SHD = 77\n",
      "Dataset 8: SHD = 77\n",
      "Dataset 9: SHD = 73\n",
      "Dataset 10: SHD = 79\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nn_struct: 77.0\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nn_struct: 88.4\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_nn_struct\n",
      "Dataset 1: SHD = 21\n",
      "Dataset 2: SHD = 17\n",
      "Dataset 3: SHD = 24\n",
      "Dataset 4: SHD = 27\n",
      "Dataset 5: SHD = 17\n",
      "Dataset 6: SHD = 26\n",
      "Dataset 7: SHD = 21\n",
      "Dataset 8: SHD = 25\n",
      "Dataset 9: SHD = 33\n",
      "Dataset 10: SHD = 16\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_nn_struct: 22.7\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_nn_struct: 25.810000000000002\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nnadd_struct\n",
      "Dataset 1: SHD = 88\n",
      "Dataset 2: SHD = 92\n",
      "Dataset 3: SHD = 82\n",
      "Dataset 4: SHD = 90\n",
      "Dataset 5: SHD = 68\n",
      "Dataset 6: SHD = 83\n",
      "Dataset 7: SHD = 80\n",
      "Dataset 8: SHD = 62\n",
      "Dataset 9: SHD = 77\n",
      "Dataset 10: SHD = 78\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nnadd_struct: 80.0\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nnadd_struct: 80.2\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_linear_struct\n",
      "Dataset 1: SHD = 40\n",
      "Dataset 2: SHD = 42\n",
      "Dataset 3: SHD = 44\n",
      "Dataset 4: SHD = 39\n",
      "Dataset 5: SHD = 33\n",
      "Dataset 6: SHD = 38\n",
      "Dataset 7: SHD = 42\n",
      "Dataset 8: SHD = 35\n",
      "Dataset 9: SHD = 39\n",
      "Dataset 10: SHD = 38\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_linear_struct: 39.0\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_linear_struct: 9.8\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_linear_struct\n",
      "Dataset 1: SHD = 8\n",
      "Dataset 2: SHD = 11\n",
      "Dataset 3: SHD = 8\n",
      "Dataset 4: SHD = 10\n",
      "Dataset 5: SHD = 12\n",
      "Dataset 6: SHD = 18\n",
      "Dataset 7: SHD = 10\n",
      "Dataset 8: SHD = 6\n",
      "Dataset 9: SHD = 14\n",
      "Dataset 10: SHD = 6\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_linear_struct: 10.3\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_linear_struct: 12.41\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nn_struct\n",
      "Dataset 1: SHD = 34\n",
      "Dataset 2: SHD = 36\n",
      "Dataset 3: SHD = 40\n",
      "Dataset 4: SHD = 35\n",
      "Dataset 5: SHD = 45\n",
      "Dataset 6: SHD = 41\n",
      "Dataset 7: SHD = 34\n",
      "Dataset 8: SHD = 42\n",
      "Dataset 9: SHD = 39\n",
      "Dataset 10: SHD = 43\n",
      "Mean SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nn_struct: 38.9\n",
      "Variance of SHD for /home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nn_struct: 14.09\n",
      "Processing data directory: /home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_linear_struct\n",
      "Dataset 1: SHD = 75\n",
      "Dataset 2: SHD = 96\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store SHD values and statistics for each data directory\n",
    "shd_stats_per_dir = {}\n",
    "\n",
    "# List of data directories to iterate through\n",
    "data_dirs = [\n",
    "    os.path.join('/home/ethan/IFT6168/project/dcdi/data/perfect', d)\n",
    "    for d in os.listdir('/home/ethan/IFT6168/project/dcdi/data/perfect')\n",
    "    if os.path.isdir(os.path.join('/home/ethan/IFT6168/project/dcdi/data/perfect', d)) and d != 'sachs_intervention'\n",
    "]\n",
    "\n",
    "# Iterate through each data directory\n",
    "for data_dir in data_dirs:\n",
    "    print(f\"Processing data directory: {data_dir}\")\n",
    "    \n",
    "    shd_values = []  # Reset SHD values for the current directory\n",
    "    \n",
    "    # Iterate through the 10 datasets in the current directory\n",
    "    for i in range(1, 11):\n",
    "        # Load the DAG and observational data\n",
    "        dag_path = os.path.join(data_dir, f'DAG{i}.npy')\n",
    "        obs_data_path = os.path.join(data_dir, f'data{i}.npy')\n",
    "        \n",
    "        dag = np.load(dag_path)  # Ground truth DAG\n",
    "        obs_data = np.load(obs_data_path)  # Observational data\n",
    "        \n",
    "        # Run NOTEARS linear\n",
    "        lambda1 = 0.1  # Regularization parameter\n",
    "        w_threshold = 0.3  # Threshold for edge weights\n",
    "        W_est = linear.notears_linear(obs_data, lambda1=lambda1, loss_type='l2')\n",
    "        W_est[np.abs(W_est) < w_threshold] = 0  # Apply thresholding\n",
    "        \n",
    "        # Compute the SHD (Structural Hamming Distance)\n",
    "        shd = np.sum((W_est != 0) != (dag != 0))  # Compare adjacency matrices\n",
    "        shd_values.append(shd)\n",
    "        \n",
    "        # Print the SHD for the current dataset\n",
    "        print(f\"Dataset {i}: SHD = {shd}\")\n",
    "    \n",
    "    # Compute the mean and variance of SHD values for the current directory\n",
    "    mean_shd = np.mean(shd_values)\n",
    "    variance_shd = np.var(shd_values)\n",
    "    \n",
    "    # Store the full SHD values and statistics in the dictionary\n",
    "    shd_stats_per_dir[data_dir] = {\n",
    "        'shd_values': shd_values,\n",
    "        'mean_shd': mean_shd,\n",
    "        'variance_shd': variance_shd\n",
    "    }\n",
    "    \n",
    "    print(f\"Mean SHD for {data_dir}: {mean_shd}\")\n",
    "    print(f\"Variance of SHD for {data_dir}: {variance_shd}\")\n",
    "\n",
    "# Display the SHD statistics for all directories\n",
    "print(\"SHD Statistics per Data Directory:\")\n",
    "print(shd_stats_per_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "114f70de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ethan/IFT6168/project/dcdi/data/perfect/sachs_intervention',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nnadd_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_nn_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nnadd_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nn_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_nn_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_nnadd_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_linear_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e10_n10000_linear_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p10_e40_n10000_nn_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e80_n10000_linear_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_linear_struct',\n",
       " '/home/ethan/IFT6168/project/dcdi/data/perfect/data_p20_e20_n10000_nnadd_struct']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dirs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_conda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
